indexmatrix <- matrix(nrow = length(dictionary), ncol = length(df[,j]))
indexmatrix[1:4]
indexmatrix[1:4,1:4]
dictionary[1]
which("AVALANCHE" == dictionary)
grepl("AVALANCHE", df[,5])
sum(grepl("AVALANCHE", df[,5]))
splitRow <- function(df, j, dictionary) {
# A matrix of logicals with rows indexed by `dictionary`. Row `word` is
#        grepl(toupper(word), toupper(df[,j]))
indexmatrix <- matrix(nrow = length(dictionary), ncol = length(df[,j]))
for (i in 1:length(dictionary)) {
indexmatrix[i,] <- grepl(dictionary[i], df[,j])
}
# For column i of `indexmatrix` find the first TRUE and go to row i in df and change the entry of df$x to the `word` corresponding to the TRUE. If there are more TRUEs in column i, then append new rows - copies of the row just edited - with the `word`s corresponding to the TRUEs.
for (i in 1:ncol(indexmatrix)) {
first <- TRUE
while (sum(indexmatrix[,i]) > 0) {
wordindex <- which(indexmatrix[,i])[1]
if (first == TRUE) {
df[i,j] <- dictionary[wordindex]
first <- FALSE
}
else {
duprow <- df[i,]
duprow[j] <- dictionary[wordindex]
df <- rbind(df, duprow)
}
indexmatrix[wordindex,i] <- FALSE
}
}
df
}
storm2 <- splitRow(df = storm, j = 5, dictionary = events)
storm2$EVTYPE
unique(storm2$EVTYPE)
unique(storm$EVTYPE)
rm(df)
rm(indexmatrix)
rm(myindexmatrix)
rm(storm)
rm(storm2)
storm <- beginrecat
psums <- tapply(storm$PROPDMG, storm$EVTYPE, sum)
csums <- tapply(storm$CROPDMG, storm$EVTYPE, sum)
fsums <- tapply(storm$FATALITIES, storm$EVTYPE, sum)
isums <- tapply(storm$INJURIES, storm$EVTYPE, sum)
storm <- data.frame(PDMG = psums[!(is.na(psums))], CDMG = csums[!(is.na(csums))],
FAT = fsums[!(is.na(fsums))], INJ = isums[!(is.na(isums))])
storm$EVTYPE <- rownames(storm)
rownames(storm) <- NULL
0.01 * total / dim(storm)[1]
total <- as.numeric(colSums(storm[1:4]))
storm <- storm[storm$PDMG > 0.01 * total[1] / dim(storm)[1] |
storm$CDMG > 0.01 * total[2] / dim(storm)[1] |
storm$FAT > 0.01 * total[3] / dim(storm)[1] |
storm$INJ > 0.01 * total[4] / dim(storm)[1],]
splitRow <- function(df, j, dictionary) {
# A matrix of logicals with rows indexed by `dictionary`. Row `word` is
#        grepl(toupper(word), toupper(df[,j]))
indexmatrix <- matrix(nrow = length(dictionary), ncol = length(df[,j]))
for (i in 1:length(dictionary)) {
indexmatrix[i,] <- grepl(dictionary[i], df[,j])
}
# For column i of `indexmatrix` find the first TRUE and go to row i in df and change the entry of df$x to the `word` corresponding to the TRUE. If there are more TRUEs in column i, then append new rows - copies of the row just edited - with the `word`s corresponding to the TRUEs.
for (i in 1:ncol(indexmatrix)) {
first <- TRUE
while (sum(indexmatrix[,i]) > 0) {
wordindex <- which(indexmatrix[,i])[1]
if (first == TRUE) {
df[i,j] <- dictionary[wordindex]
first <- FALSE
}
else {
duprow <- df[i,]
duprow[j] <- dictionary[wordindex]
df <- rbind(df, duprow)
}
indexmatrix[wordindex,i] <- FALSE
}
}
df
}
storm2 <- splitrow(df = storm, j = 5, dictionary = events)
storm2 <- splitRow(df = storm, j = 5, dictionary = events)
storm[storm$EVTYPE != storm2$EVTYPE,]
head(storm)
head(storm2)
storm
storm[1]
storm[1,]
rownames(storm)
storm
storm2
cbind(storm$EVTYPE, storm2$EVTYPE)
cbind(c(storm$EVTYPE, 1:11), storm2$EVTYPE)
storm <- beginrecat
psums <- tapply(storm$PROPDMG, storm$EVTYPE, sum)
csums <- tapply(storm$CROPDMG, storm$EVTYPE, sum)
fsums <- tapply(storm$FATALITIES, storm$EVTYPE, sum)
isums <- tapply(storm$INJURIES, storm$EVTYPE, sum)
storm <- data.frame(PDMG = psums[!(is.na(psums))], CDMG = csums[!(is.na(csums))],
FAT = fsums[!(is.na(fsums))], INJ = isums[!(is.na(isums))])
storm$EVTYPE <- rownames(storm)
rownames(storm) <- NULL
total <- as.numeric(colSums(storm[1:4]))
storm <- storm[storm$PDMG > 0.01 * total[1] / dim(storm)[1] |
storm$CDMG > 0.01 * total[2] / dim(storm)[1] |
storm$FAT > 0.01 * total[3] / dim(storm)[1] |
storm$INJ > 0.01 * total[4] / dim(storm)[1],]
events <- c("AVALANCHE", "BLIZZARD", "COASTAL STORM", "COLD", "DROUGHT",
"DUST STORM", "FIRE", "FLOOD", "FOG", "FREEZE", "HAIL", "HEAT",
"HIGH SURF/STORM SURGE", "HURRICANE/TYPHOON", "ICE", "LANDSLIDE",
"LIGHTNING", "OTHER", "RAIN", "SNOW", "THUNDERSTORM/WIND", "TORNADO",
"TROPICAL STORM", "TSUNAMI", "WINTRY MIX")
storm2 <- splitRow(df = storm, j = 5, dictionary = events)
cbind(c(storm$EVTYPE, 1:15), storm2$EVTYPE)
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("AVA", storm$EVTYPE)]
storm$EVTYPE[grep("AVALANCE", storm$EVTYPE)] <- "AVALANCHE"
storm$EVTYPE[grep("AVA", storm$EVTYPE) & !(storm$EVTYPE %in% events)]
unique(storm$EVTYPE[grep("AVA", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("AVA", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("FREE", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
rm(storm2)
storm <- beginrecat
psums <- tapply(storm$PROPDMG, storm$EVTYPE, sum)
csums <- tapply(storm$CROPDMG, storm$EVTYPE, sum)
fsums <- tapply(storm$FATALITIES, storm$EVTYPE, sum)
isums <- tapply(storm$INJURIES, storm$EVTYPE, sum)
storm <- data.frame(PDMG = psums[!(is.na(psums))], CDMG = csums[!(is.na(csums))],
FAT = fsums[!(is.na(fsums))], INJ = isums[!(is.na(isums))])
storm$EVTYPE <- rownames(storm)
rownames(storm) <- NULL
total <- as.numeric(colSums(storm[1:4]))
storm <- storm[storm$PDMG > 0.01 * total[1] / dim(storm)[1] |
storm$CDMG > 0.01 * total[2] / dim(storm)[1] |
storm$FAT > 0.01 * total[3] / dim(storm)[1] |
storm$INJ > 0.01 * total[4] / dim(storm)[1],]
storm <- splitRow(df = storm, j = 5, dictionary = events)
storm$EVTYPE[grep("AVALANCE", storm$EVTYPE)]
storm$EVTYPE[grep("AVALANCE", storm$EVTYPE)] <- "AVALANCHE"
unique(storm$EVTYPE[grep("AVALANCE", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grep("FREE", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("FREE", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("FREE", storm$EVTYPE)] <- "FREEZE"
unique(storm$EVTYPE[grepl("HUR", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("HUR", storm$EVTYPE)] <- "HURRICANE/TYPHOON"
unique(storm$EVTYPE[grepl("TYP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("TYP", storm$EVTYPE)] <- "HURRICANE/TYPHOON"
unique(storm$EVTYPE[grepl("COLD", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("COOL", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("COOL", storm$EVTYPE)] <- "COLD"
unique(storm$EVTYPE[grepl("thu", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("THU", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("TU", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("THU", storm$EVTYPE)] <- "THUNDERSTORM/WIND"
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("WIND", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("CHILL", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("CHILL", storm$EVTYPE)] <- "COLD"
unique(storm$EVTYPE[grepl("WIND", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
storm[!(storm$EVTYPE %in% events),]
colSums(storm[!(storm$EVTYPE %in% events),1:4])
unique(storm$EVTYPE[grepl("WIND", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("WHIRL", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("WHIRLWIND", storm$EVTYPE)] <- "TORNADO"
storm$EVTYPE[grep("WIND", storm$EVTYPE)] <- "THUNDERSTORM/WIND"
storm[!(storm$EVTYPE %in% events),]
unique(storm$EVTYPE[grepl("SURF", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("SURF", storm$EVTYPE)] <- "HIGH SURF/STORM SURGE"
storm[!(storm$EVTYPE %in% events),]
storm$EVTYPE[grep("SURG", storm$EVTYPE)] <- "HIGH SURF/STORM SURGE"
storm <- beginrecat
psums <- tapply(storm$PROPDMG, storm$EVTYPE, sum)
csums <- tapply(storm$CROPDMG, storm$EVTYPE, sum)
fsums <- tapply(storm$FATALITIES, storm$EVTYPE, sum)
isums <- tapply(storm$INJURIES, storm$EVTYPE, sum)
storm <- data.frame(PDMG = psums[!(is.na(psums))], CDMG = csums[!(is.na(csums))],
FAT = fsums[!(is.na(fsums))], INJ = isums[!(is.na(isums))])
storm$EVTYPE <- rownames(storm)
rownames(storm) <- NULL
total <- as.numeric(colSums(storm[1:4]))
storm <- storm[storm$PDMG > 0.01 * total[1] / dim(storm)[1] |
storm$CDMG > 0.01 * total[2] / dim(storm)[1] |
storm$FAT > 0.01 * total[3] / dim(storm)[1] |
storm$INJ > 0.01 * total[4] / dim(storm)[1],]
storm <- splitRow(df = storm, j = 5, dictionary = events)
storm$EVTYPE[grep("AVALANCE", storm$EVTYPE)] <- "AVALANCHE"
storm$EVTYPE[grep("FREE", storm$EVTYPE)] <- "FREEZE"
storm$EVTYPE[grep("HUR", storm$EVTYPE)] <- "HURRICANE/TYPHOON"
storm$EVTYPE[grep("TYP", storm$EVTYPE)] <- "HURRICANE/TYPHOON"
storm$EVTYPE[grep("COOL", storm$EVTYPE)] <- "COLD"
storm$EVTYPE[grep("THU", storm$EVTYPE)] <- "THUNDERSTORM/WIND"
storm$EVTYPE[grep("CHILL", storm$EVTYPE)] <- "COLD"
storm$EVTYPE[grep("WHIRLWIND", storm$EVTYPE)] <- "TORNADO"
storm$EVTYPE[grep("WIND", storm$EVTYPE)] <- "THUNDERSTORM/WIND"
storm$EVTYPE[grep("SURF", storm$EVTYPE)] <- "HIGH SURF/STORM SURGE"
unique(storm$EVTYPE[grepl("SURG", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("SURG", storm$EVTYPE)] <- "HIGH SURF/STORM SURGE"
unique(storm$EVTYPE[!(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("FLD", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm$EVTYPE[grep("FLD", storm$EVTYPE)] <- "FLOOD"
unique(storm$EVTYPE[grepl("RIP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm <- formatEVTYPE
unique(storm$EVTYPE[grepl("RIP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("MISHAP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("ACC", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("ACC", toupper(storm$EVTYPE)) & !(storm$EVTYPE %in% events)])
storm$EVTYPE <- toupper(storm$EVTYPE)
unique(storm$EVTYPE[grepl("ACC", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
unique(storm$EVTYPE[grepl("MISHAP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm <- storm[-grep(toupper("MISHAP"), storm$EVTYPE), ]
storm <- storm[-grep(toupper("ACCIDENT"), storm$EVTYPE), ]
storm <- storm[-grep(toupper("DROWNING"), storm$EVTYPE), ]
unique(storm$EVTYPE[grepl("APACHE", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm <- storm[-grep(toupper("APACHE COUNTY"), storm$EVTYPE), ]
unique(storm$EVTYPE[grepl("RIP", storm$EVTYPE) & !(storm$EVTYPE %in% events)])
storm[grepl("RIP", storm$EVTYPE),]
colSums(storm[grepl("RIP", storm$EVTYPE),c(5,7)])
x <- c(140, 132, 138, 135, 150, 151, 148, 146, 135, 130)
?matrix
matrix(x, nrow = 5, byrow = TRUE)
as.data.frame(matrix(x, nrow = 5, byrow = TRUE))
x <- as.data.frame(matrix(x, nrow = 5, byrow = TRUE))
x
?t.test
t.test(V1, V2, data = x)
t.test(x$V1, x$V2, paired = TRUE)
data(mtcars)
mean(mtcars$mpg)
mean(mtcars$mpg) + qnorm(.025)*sd(mtcars$mpg)/sqrt(length(mtcars$mpg))
mean(mtcars$mpg) + qnorm(.05)*sd(mtcars$mpg)/sqrt(length(mtcars$mpg))
mean(mtcars$mpg) + c(-1,1)*qnorm(.05)*sd(mtcars$mpg)/sqrt(length(mtcars$mpg))
t.test(mtcars$mpg[cyl == 4], mtcars$mpg[cyl == 6], var.equal = FALSE)
t.test(mtcars$mpg[mtcars$cyl == 4], mtcars$mpg[mtcars$cyl == 6], var.equal = FALSE)
qnorm(0.05)
qnorm(0.025)
1100 + c(-1, 1)*qt(.975, 8)*30/sqrt(9)
1077+1123
1100 + c(-1, 1)*qt(.975,8)/qt(.95, 8)
1078 + c(-1, 1)*qt(.975,8)/qt(.95, 8)
18/sqrt(5)
pt(-18/sqrt(5), 16)
pt(18/sqrt(5), 16)
sd(c(rep(-3,7), c(-1,1)*5))
sd(c(rep(-3,7), c(-1,1)*3))
sd(c(rep(-3,7), c(-1,1)*2))
sd(c(rep(-3,7), c(-1,1)*1))
sd(c(rep(-3,7), c(-1,1)*1/sqrt(2)))
sd(c(rep(-3,7), c(-1,1)*1/2)
)
sd(c(rep(-3,7), c(-1,1)*1/5))
sd(c(rep(-3,7), c(-1,1)*1/9))
sd(c(rep(-3,7), c(-1,1)*0))
c(rep(-3,7), c(-1,1)*0)
c(rep(-3,7), -3 + c(-1,1)*0)
sd(c(rep(-3,7), -3 + c(-1,1)*0))
sd(c(rep(-3,7), -3 + c(-1,1)*1))
sd(c(rep(-3,7), -3 + c(-1,1)*2))
treatment <- sd(c(rep(-3,7), -3 + c(-1,1)*2))
sd(c(rep(-3,7), -3 + c(-1,1)*2))
sd(c(rep(-3,7), -3 + c(-1,1)*1.5))
sd(c(rep(-3,7), -3 + c(-1,1)*3))
treatment <- sd(c(rep(-3,7), -3 + c(-1,1)*3))
sd(c(rep(1,7), 1 + c(-1,1)*3.6))
placebo <- sd(c(rep(1,7), 1 + c(-1,1)*3.6))
t.test(treatment, placebo, var.equal = TRUE)
x <- as.factor(c("coke", "coke", "coke", "pepsi"))
x
fisher.test(x, alternative = "one.sided")
contingency <- matrix(c(3,1), nrow = 1)
contingency
fisher.test(contingency, alternative = "greater")
x <- cbind(c(1,1,1,0), c(0,0,0,1))
x
fisher.test(x, alternative = "greater")
fisher.test(x, alternative = "two.sided")
fisher.test(t(x), alternative = "two.sided")
fisher.test(t(x), alternative = "greater")
binom.test(x=x, n=n, alt="greater")
binom.test(x=3, n=4, alt="greater")
10/1787
1/100
x <- rep(0, 1787)
sd(x)
x[1:10] <- 1
x
sd(x)
(10/1787 - 1/100)/(sd(x)/sqrt(1787))
t <- (10/1787 - 1/100)/(sd(x)/sqrt(1787))
pt(t, 1786)
?test
??test
?t.test
?.test
??.test
power.t.test(n = 100, delta = 0.01, sd = 0.04, alternative = "one.sided")$power
power.t.test(n = 100, delta = 0.01, sd = 0.04, alternative = "one.sided", type = "one.sample")$power
?power.t.test
power.t.test(power = .9, delta = 0.01, sd = 0.04, alternative = "one.sided", type = "one.sample")$n
?poisson.test
4.75+7.5+2+13.5+3.25
data(shuttle)
library(MASS)
data(shuttle)
myglm <- glm(auto ~ wind, family = binomial, data = shuttle)
?shuttle
myglm <- glm(use ~ wind, family = binomial, data = shuttle)
myglm
summary(myglm)
e
exp(1)
exp(-0.03181)
1/exp(-0.03181)
summary(glm(use ~ wind + magn,  family = binomial, data = shuttle))
summary(exp(glm(use ~ wind + magn,  family = binomial, data = shuttle)))
summary(glm(use ~ wind + magn,  family = binomial, data = shuttle))
exp(-3.201e-02)
summary(glm(1 - use ~ wind + magn,  family = binomial, data = shuttle))
summary(glm(I(1 - use) ~ wind + magn,  family = binomial, data = shuttle))
summary(glm(use ~ wind + magn,  family = binomial, data = shuttle))
summary(glm(I(use) ~ wind + magn,  family = binomial, data = shuttle))
summary(glm(I(1 - use) ~ wind + magn,  family = binomial, data = shuttle))
data$use
shuttle$use
library(dplyr)
revalue(shuttle$use, c("auto" = 1, "noauto" = 2))
rm(dplyr)
mutate(shuttle, use2, c("auto" = 1, "noauto" = 2))
?mutate
data("InsectSprays")
summary(glm(spray, family = "poisson", data = InsectSprays))
?InsectSprays
summary(glm(count ~ spray, family = "poisson", data = InsectSprays))
exp(0.05588 - 2.67415)
exp(0.05588 )
1/exp(0.05588 )
?offset
?rep
x <- rep(0:1, each = 50)
t <- log(rpois(100, 1))
count <- rpois(100, 10)
df <- cbind(x,t,count)
summary(glm(count~ x + offset(t), family = poisson))
df
t <- t <- log(rpois(100, 1) + 1)
summary(glm(count~ x + offset(t), family = poisson))
summary(glm(count~ x + offset(log(10) + t), family = poisson))
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(y~x)
?piecewise.linear
install.packages("SiZer")
library("SiZer")
?piecewise.linear
piecewise.linear(x, y, middle=1)
hockey <- piecewise.linear(x, y, middle=1)
plot(hockey, add = TRUE)
?abline
abline(-0.5560041, 2.0905719)
summary(hockey)
class(hockey)
hockey
hockey <- piecewise.linear(x, y, middle=1, CI=TRUE, bootstrap.samples = 1000, sig.level = 0.05)
)
hockey <- piecewise.linear(x, y, middle=1, CI=TRUE, bootstrap.samples = 1000, sig.level = 0.05)
hockey
1.3299983+0.8157337
(1.3299983+0.8157337)/2
rm(df)
rm(InsectSprays)
rm(shuttle)
rm(count)
rm(hockey)
rm(myglm)
rm(t)
rm(x)
rm(y)
clear()
?clear
dir()
library("shiny")
runApp("App-1")
runApp("stockVis")
?caret
install.packages("caret")
install.packages("caret", dependencies = c("Depends", "Suggests"))
?caret
??caret
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData2 = data.frame(predictors)
trainIndex2 = createDataPartition(diagnosis,p=0.5,list=FALSE)
training2 = adData2[trainIndex2,]
testing2 = adData2[-trainIndex2,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(SuperPlasticizer, data = concrete)
hist(concrete$SuperPlasticizer)
head(concrete)
class(concrete$SuperPlasticizer)
str(concrete)
hist(concrete$Superplasticizer)
hist(log10(concrete$Superplasticizer) + 1)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
grep("^IL", names(training))
iltrain <- training[grep("^IL", names(training))]
names(iltrain)
preProcess(iltrain, method = "pca", thresh = .8)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = training)
train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = iltrain)
train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = cbind(iltrain, training$diagnosis))
warnings()
train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = cbind(iltrain, training$diagnosis), fudge = F)
train(training$diagnosis ~ ., method = "glm", data = cbind(iltrain, training$diagnosis))
train(training$diagnosis ~ ., method = "glm", data = iltrain)
train(training$diagnosis ~ ., method = "glm", data = iltrain, preProcess = "pca", thresh = .8)
pc <-  preProcess(iltrain, method = "pca", thresh = .8)
train(training$diagnosis ~ ., method = "glm", data = pc)
pc
str(pc)
pc$rotation
train(training$diagnosis ~ ., method = "glm", data = pc$rotation)
View(iltrain)
mytrain <- cbind(training$diagnosis, iltrain)
mypc <-  preProcess(mytrain, method = "pca", thresh = .8)
predict(pc, training$diagnosis)
prcomp(iltrain)
prcomp(iltrain)$x[,1]
prcomp(iltrain)$x[,2]
preproc <- preProcess(iltrain, method = "pca", thresh = .8)
trainPC <- predict(preproc, iltrain)
?predict
trainPC
modelfit <- train(training$diagnosis ~ ., method = "glm", data = trainPC)
modelfit
modelfit2 <- train(training$diagnosis ~ ., method = "glm", data = iltrain)
modelfit2
library(devtools)
install.packages(Rtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
library(shiny)
setwd("DataProducts/DataProdApp")
runApp()
library(rsconnect)
deployApp()
runApp()
runApp()
runApp()
deployApp()
runApp()
runApp()
runApp()
dir()
shinyapps::showLogs()
runApp()
setwd("../")
rsconnect::configureApp("DataProdApp", size="small")
setwd("DataProdApp")
runApp()
shinyapps::showLogs()
?tolower
?with
?paste
runApp()
runApp()
runApp()
runApp()
runApp()
